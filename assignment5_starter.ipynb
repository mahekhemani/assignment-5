{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "speH6d9wlEHm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "FkhCRVINlEHn"
      },
      "outputs": [],
      "source": [
        "class KNN:\n",
        "    def __init__(self, k=3, distance_metric='euclidean'):\n",
        "        self.k = k\n",
        "        self.distance_metric = distance_metric\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Store the training data\n",
        "        self.X_train = np.array(X)\n",
        "        self.y_train = np.array(y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Predict labels for each point in X\n",
        "        X = np.array(X)\n",
        "        predictions = [self._predict_single(x) for x in X]\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        # Predict probabilities for each point in X\n",
        "        X = np.array(X)\n",
        "        probabilities = [self._predict_single_proba(x) for x in X]\n",
        "        return np.array(probabilities)\n",
        "\n",
        "    def _predict_single(self, x):\n",
        "        distances = self.compute_all_distances(x)\n",
        "        k_indices = np.argsort(distances)[:self.k]\n",
        "        k_nearest_labels = self.y_train[k_indices]\n",
        "        return np.argmax(np.bincount(k_nearest_labels))\n",
        "\n",
        "    def _predict_single_proba(self, x):\n",
        "        distances = self.compute_all_distances(x)\n",
        "        k_indices = np.argsort(distances)[:self.k]\n",
        "        k_nearest_labels = self.y_train[k_indices]\n",
        "        return np.mean(k_nearest_labels)\n",
        "\n",
        "    def compute_all_distances(self, x):\n",
        "        if self.distance_metric == 'euclidean':\n",
        "            return np.sqrt(np.sum((self.X_train - x) ** 2, axis=1))\n",
        "        elif self.distance_metric == 'manhattan':\n",
        "            return np.sum(np.abs(self.X_train - x), axis=1)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported distance metric\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "o1O12ncalEHo"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(train_path, test_path):\n",
        "    # Load the training and test datasets\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    test_data = pd.read_csv(test_path)\n",
        "\n",
        "    # Adjust column names as needed\n",
        "    drop_columns = ['CustomerId', 'Surname']\n",
        "    # Only drop columns that exist\n",
        "    drop_columns = [col for col in drop_columns if col in train_data.columns]\n",
        "\n",
        "    # Drop unnecessary columns from train and test data\n",
        "    train_data = train_data.drop(columns=drop_columns)\n",
        "    test_data = test_data.drop(columns=drop_columns)\n",
        "\n",
        "    # Separate features and target variable from training data\n",
        "    X_train = train_data.drop(columns=['Exited'])\n",
        "    y_train = train_data['Exited']\n",
        "\n",
        "    # For test data, keep all features\n",
        "    X_test = test_data\n",
        "\n",
        "    # Identify numerical and categorical columns\n",
        "    numerical_features = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
        "    categorical_features = ['Geography', 'Gender']\n",
        "\n",
        "    # Create transformers for numerical and categorical features\n",
        "    numerical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='mean')),  # Handle missing values\n",
        "        ('scaler', StandardScaler())  # Scale features\n",
        "    ])\n",
        "\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),  # Handle missing values\n",
        "        ('onehot', OneHotEncoder(drop='first'))  # One-hot encode and drop the first\n",
        "    ])\n",
        "\n",
        "    # Combine transformers into a preprocessor\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numerical_transformer, numerical_features),\n",
        "            ('cat', categorical_transformer, categorical_features)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Fit the preprocessor on the training data and transform both train and test sets\n",
        "    X_train_processed = preprocessor.fit_transform(X_train)\n",
        "    X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "    # Convert to DataFrame for compatibility\n",
        "    X_train_processed = pd.DataFrame(X_train_processed)\n",
        "    X_test_processed = pd.DataFrame(X_test_processed)\n",
        "\n",
        "    return X_train_processed, y_train, X_test_processed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "npOoWz1xlEHo"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "# Define cross-validation function\n",
        "def cross_validate(X, y, knn, n_splits=5):\n",
        "    # Initialize KFold cross-validation\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    # Store the AUC scores for each split\n",
        "    auc_scores = []\n",
        "\n",
        "    # Convert X and y to numpy arrays for compatibility with KNN class\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # Iterate over each split\n",
        "    for train_index, val_index in kf.split(X):\n",
        "        # Split the data into training and validation sets\n",
        "        X_train, X_val = X[train_index], X[val_index]\n",
        "        y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "        # Fit the KNN model on the training data\n",
        "        knn.fit(X_train, y_train)\n",
        "\n",
        "        # Predict probabilities on the validation set\n",
        "        y_pred_prob = knn.predict_proba(X_val)\n",
        "\n",
        "        # Calculate the ROC AUC score\n",
        "        auc_score = roc_auc_score(y_val, y_pred_prob)\n",
        "        auc_scores.append(auc_score)\n",
        "\n",
        "    # Return the average AUC score across all splits and the individual scores\n",
        "    return np.mean(auc_scores), auc_scores\n",
        "\n",
        "# The function is now implemented and ready for use.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QrZzVvklEHo",
        "outputId": "df5fa540-fd72-4285-de05-004d6b08451f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.8489186719463905, 0.8514589469808541, 0.8912643861892584]\n",
            "Mean AUC score: 0.8638806683721677\n",
            "Optimal k found: 13 with AUC: 0.889619440983877\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data\n",
        "X, y, X_test = preprocess_data('/content/train.csv', '/content/test.csv')\n",
        "\n",
        "# Create and evaluate model\n",
        "knn = KNN(k=5, distance_metric='euclidean')\n",
        "\n",
        "# Sample a fraction of the dataset for testing (10% of the data)\n",
        "X_sampled = X.sample(frac=0.1, random_state=42)  # Use 10% of the data\n",
        "y_sampled = y.loc[X_sampled.index]\n",
        "\n",
        "# Perform cross-validation with the smaller subset\n",
        "mean_auc, auc_scores = cross_validate(X_sampled, y_sampled, knn, n_splits=3)  # Use fewer splits for testing\n",
        "print(\"Cross-validation scores:\", auc_scores)\n",
        "print(\"Mean AUC score:\", mean_auc)\n",
        "\n",
        "# Hyperparameter tuning (example: exploring different values for k)\n",
        "best_k = 5\n",
        "best_auc = mean_auc\n",
        "\n",
        "for k in range(1, 21):  # Test different values for k (1 to 20)\n",
        "    knn = KNN(k=k, distance_metric='euclidean')\n",
        "    mean_auc, _ = cross_validate(X_sampled, y_sampled, knn, n_splits=3)  # Use smaller subset for tuning\n",
        "    if mean_auc > best_auc:\n",
        "        best_auc = mean_auc\n",
        "        best_k = k\n",
        "\n",
        "print(f\"Optimal k found: {best_k} with AUC: {best_auc}\")\n",
        "\n",
        "# Train on the full dataset with optimal hyperparameters and make predictions on the test set\n",
        "knn = KNN(k=best_k, distance_metric='euclidean')\n",
        "knn.fit(np.array(X), np.array(y))\n",
        "test_predictions = knn.predict_proba(np.array(X_test))\n",
        "\n",
        "# Save test predictions to match the submission format\n",
        "test_ids = pd.read_csv('/content/test.csv')['id']\n",
        "submission = pd.DataFrame({'id': test_ids, 'Exited': test_predictions})\n",
        "submission.to_csv('submissions.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cs506",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}